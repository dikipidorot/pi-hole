# 官方文档
# http://hub.docker.com/ollama/ollama
# https://www.ollama.com

# Llama2中文预训练模型(7b）
# ollama pull llamafamily/atom-7b-chat
# Llama2中文预训练模型(8b）
# ollama pull llamafamily/llama3-chinese-8b-instruct
# 列出模型
# ollama list
# 运行模型
# ollama run 【模型名字】
# 删除模型
# ollama rm 【模型名字】
# 7b大小的模型至少需要8G RAM
# 8b大小的模型至少需要16G RAM
# 13b大小的模型至少需要32G RAM
# 70b大小的模型至少需要64G RAM

---
version: "3"
# 最后编辑时间：2024-05-20
services:
  ollama:
    image: ollama/ollama
    # 镜像地址
    container_name: ollama
    # 容器名字
    hostname: ollama
    # 主机名
    # environment:
    volumes:
      - /share/container-station-data/ollama:/root/.ollama
      # 配置文件目录
    # network_mode: bridge
    network_mode: host
    # host模式需要容器内的端口不被占用，不需要端口映射，后续端口映射全都开头加#注释掉，否则注释掉这条
    # ports:
      # - 11434:11434/tcp
      # WebUI 端口
    restart: always
    # 重启策略，可根据实际情况而选择 no/always/unless-stopped/on-failure/on-failure:3
      