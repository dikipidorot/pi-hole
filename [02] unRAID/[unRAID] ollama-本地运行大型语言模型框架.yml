# 官方文档
# http://hub.docker.com/ollama/ollama
# https://www.ollama.com

# Llama2中文预训练模型(7b）
# ollama pull llamafamily/atom-7b-chat
# Llama2中文预训练模型(8b）
# ollama pull llamafamily/llama3-chinese-8b-instruct
# 列出模型
# ollama list
# 运行模型
# ollama run 【模型名字】
# 删除模型
# ollama rm 【模型名字】
# 7b大小的模型至少需要8G RAM
# 8b大小的模型至少需要16G RAM
# 13b大小的模型至少需要32G RAM
# 70b大小的模型至少需要64G RAM


---
version: "3"
# 最后编辑时间：2024-05-20
services:
  ollama:
    image: ollama/ollama
    # 镜像地址
    container_name: ollama
    # 容器名字
    hostname: ollama
    # 主机名
    # environment:
    volumes:
      - /mnt/user/appdata/ollama:/root/.ollama
      # 配置文件目录
    # network_mode: bridge
    network_mode: host
    # host模式需要容器内的端口不被占用，不需要端口映射，后续端口映射全都开头加#注释掉，否则注释掉这条
    # ports:
      # - 11434:11434/tcp
      # WebUI 端口
    restart: always
    # 重启策略，可根据实际情况而选择 no/always/unless-stopped/on-failure/on-failure:3
    labels:
      net.unraid.docker.managed: dockerman
      net.unraid.docker.webui: http://[IP]:[PORT:11434]
      # 适用于unraid界面打开WebUI，注意端口号写的是容器端口，如有自定义，自行修改
      net.unraid.docker.icon: /mnt/user/LOGO/ollama.png
      # 适用于unraid的图标，可以写unRAID的路径地址，也可以写一个图标地址(局域网或广域网均可)
      # 注意：通过compose创建的docker容器，无法在unRAID上进行编辑
      